{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2.65\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "print(yf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pickle\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\navee\\AppData\\Local\\Temp\\ipykernel_17420\\2509901305.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  df = yf.download(\"TSLA\", start=start, end=end)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset head:\n",
            " Price           Close       High        Low       Open    Volume\n",
            "Ticker           TSLA       TSLA       TSLA       TSLA      TSLA\n",
            "Date                                                            \n",
            "2015-01-02  14.620667  14.883333  14.217333  14.858000  71466000\n",
            "2015-01-05  14.006000  14.433333  13.810667  14.303333  80527500\n",
            "2015-01-06  14.085333  14.280000  13.614000  14.004000  93928500\n",
            "2015-01-07  14.063333  14.318667  13.985333  14.223333  44526000\n",
            "2015-01-08  14.041333  14.253333  14.000667  14.187333  51637500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "start = datetime.datetime(2015, 1, 1)\n",
        "end = datetime.datetime.today()\n",
        "df = yf.download(\"TSLA\", start=start, end=end)\n",
        "df = df.sort_index()\n",
        "print(\"Dataset head:\\n\", df.head())\n",
        "\n",
        "# Use OHLCV features\n",
        "features = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "\n",
        "\n",
        "df['Return'] = df['Close'].pct_change()\n",
        "df = df.dropna()\n",
        "\n",
        "# Features (X) = OHLCV, Target (y) = Return\n",
        "X = features.iloc[1:].values   # drop first row (due to NaN return)\n",
        "y = df['Return'].values        # returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler_X = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_X = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_y = scaler_y.fit_transform(y.reshape(-1,1))\n",
        "\n",
        "# Save scalers\n",
        "with open(\"scaler_X.pkl\",\"wb\") as f:\n",
        "    pickle.dump(scaler_X,f)\n",
        "with open(\"scaler_y.pkl\",\"wb\") as f:\n",
        "    pickle.dump(scaler_y,f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2703\n"
          ]
        }
      ],
      "source": [
        "print(len(scaled_X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (2102, 60, 5)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "training_data_len = int(len(scaled_X) * 0.8)\n",
        "train_X, test_X = scaled_X[:training_data_len], scaled_X[training_data_len:]\n",
        "train_y, test_y = scaled_y[:training_data_len], scaled_y[training_data_len:]\n",
        "\n",
        "\n",
        "def create_sequences(X, y, look_back=60):\n",
        "    x_seq, y_seq = [], []\n",
        "    for i in range(look_back, len(X)):\n",
        "        x_seq.append(X[i-look_back:i])\n",
        "        y_seq.append(y[i])\n",
        "    return np.array(x_seq), np.array(y_seq)\n",
        "\n",
        "look_back = 60\n",
        "x_train, y_train = create_sequences(train_X, train_y, look_back)\n",
        "x_test, y_test = create_sequences(test_X, test_y, look_back)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "h=tf.keras.losses.MeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\navee\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - loss: 0.0260 - val_loss: 0.0079\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 0.0079 - val_loss: 0.0085\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - loss: 0.0080 - val_loss: 0.0077\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - loss: 0.0077 - val_loss: 0.0080\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 0.0075 - val_loss: 0.0092\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 0.0073 - val_loss: 0.0083\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - loss: 0.0073 - val_loss: 0.0081\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - loss: 0.0072 - val_loss: 0.0082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    LSTM(130, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(130, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(1)  \n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"MeanSquaredError\")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        ")\n",
        "\n",
        "# Save Model\n",
        "model.save(\"model_returns.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPN/mCuawDwIyHJc/4dKNsj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
